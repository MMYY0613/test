import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import matplotlib as mpl
from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA
from pathlib import Path
import itertools
import warnings
import seaborn as sns

warnings.simplefilter('ignore')

# =========================================================
# 1. è¨­å®šãƒ»å®šæ•°
# =========================================================
CONFIG = {
    "data_path": "./data/all_q_merged.csv",
    "output_dir": "./output_pca_final",
    "train_range": ("2015-01-01", "2016-06-30"),
    "test_steps": 1,
    "pc_max": 3,
    "p_lag": 1,
    "ridge": 1.0,
    "do_irf": True,
}

BASE_LEVELS = {
    "GDP": 500000, "NIKKEI": 20000, "USD_JPY": 110, "UNEMP_RATE": 3.0,
    "JGB_1Y": 0.1, "JGB_2Y": 0.2, "JGB_3Y": 0.3, "CPI": 100
}

TARGET_MACRO = list(BASE_LEVELS.keys())

SECTOR_COLS = [
    "RET_FOODS", "RET_ENERGY_RESOURCES", "RET_CONSTRUCTION_MATERIALS", "RET_RAW_MAT_CHEM",
    "RET_PHARMACEUTICAL", "RET_AUTOMOBILES_TRANSP_EQUIP", "RET_STEEL_NONFERROUS",
    "RET_MACHINERY", "RET_ELEC_APPLIANCES_PRECISION", "RET_IT_SERV_OTHERS",
    "RET_ELECTRIC_POWER_GAS", "RET_TRANSPORT_LOGISTICS", "RET_COMMERCIAL_WHOLESALE",
    "RET_RETAIL_TRADE", "RET_BANKS", "RET_FIN_EX_BANKS", "RET_REAL_ESTATE", "RET_TEST"
]

mpl.rcParams["axes.unicode_minus"] = False
plt.rcParams['font.family'] = ["Hiragino Sans"]

# =========================================================
# 2. ãƒ­ã‚¸ãƒƒã‚¯é–¢æ•°
# =========================================================
def smart_transform(series, name):
    if (series <= 0).any() or "JGB" in name or "UNEMP" in name:
        return series.diff(), "DIFF"
    return np.log(series).diff(), "LOGDIFF"

def prepare_aligned(df_raw):
    m_work = pd.DataFrame(index=df_raw.index)
    meta = {}
    for col in TARGET_MACRO:
        if col in df_raw.columns:
            ts, method = smart_transform(df_raw[col], col)
            m_work[f"{col}_{method}"] = ts
            meta[f"{col}_{method}"] = {"orig": col, "method": method}
    m_df = m_work.dropna()
    s_raw = df_raw[[c for c in SECTOR_COLS if c in df_raw.columns]].interpolate(limit_direction='both')
    s_diff = s_raw.dropna() if all(c.startswith("RET_") for c in s_raw.columns) else s_raw.diff().dropna()
    common = s_diff.index.intersection(m_df.index)
    return s_diff.loc[common], m_df.loc[common], common, meta

def pca_no_leak(X_all, t_start, t_end, t_size, k_use=3):
    X_tr = X_all.iloc[t_start:t_end]
    X_te = X_all.iloc[t_end:t_end+t_size]
    sc = StandardScaler(); pca = PCA(n_components=k_use)
    Ztr = pca.fit_transform(sc.fit_transform(X_tr))
    Zte = pca.transform(sc.transform(X_te))
    cols = [f"PC{i+1}" for i in range(k_use)]
    pc_df = pd.concat([pd.DataFrame(Ztr, index=X_tr.index, columns=cols),
                       pd.DataFrame(Zte, index=X_te.index, columns=cols)])
    return pc_df.diff().dropna(), pca.explained_variance_ratio_

def make_design(endog, exog, p):
    Y = endog.values
    X_parts = [np.ones((len(endog), 1))]
    for lag in range(1, p+1):
        X_parts.append(endog.shift(lag).values)
    if exog is not None and not exog.empty:
        X_parts.append(exog.values)
    X = np.concatenate(X_parts, axis=1)
    valid = ~np.isnan(X).any(axis=1) & ~np.isnan(Y).any(axis=1)
    return Y[valid], X[valid]

def analyze_pca_details(pca, sector_df, pc_cols, root_dir, t_start, t_end, t_size):
    """PCAåˆ†æï¼šæ¨™æº–åŒ–ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ã®ç”Ÿã‚¹ã‚³ã‚¢ç®—å‡ºãƒ»ãƒ—ãƒ­ãƒƒãƒˆãƒ»è² è·é‡CSVå‡ºåŠ›ï¼ˆè»¸ãƒ©ãƒ™ãƒ«è¿½åŠ ç‰ˆï¼‰"""
    pca_dir = root_dir / "pca_analysis"
    pca_dir.mkdir(exist_ok=True)
    
    # è¨“ç·´+ãƒ†ã‚¹ãƒˆæœŸé–“ã®ãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡ºã—ã¦æ¨™æº–åŒ–
    X_target = sector_df.iloc[t_start : t_end + t_size]
    sc = StandardScaler()
    sc.fit(sector_df.iloc[t_start : t_end])
    X_scaled = sc.transform(X_target)
    
    # ä¸»æˆåˆ†ã‚¹ã‚³ã‚¢ã®ç®—å‡º
    scores = pca.transform(X_scaled)
    score_df = pd.DataFrame(scores, index=X_target.index, columns=pc_cols)
    
    # ã‚¹ã‚³ã‚¢ã®CSVå‡ºåŠ›
    score_df.to_csv(pca_dir / "ä¸»æˆåˆ†ã‚¹ã‚³ã‚¢_ç”Ÿãƒ‡ãƒ¼ã‚¿.csv", encoding="utf-8-sig")

    expl = pca.explained_variance_ratio_
    components = pca.components_.copy()
    
    # ç¬¦å·ã®åè»¢å‡¦ç†ï¼ˆè§£é‡ˆã‚’å®¹æ˜“ã«ã™ã‚‹ãŸã‚ï¼‰
    for i in range(components.shape[0]):
        if np.mean(components[i]) < 0:
            components[i] *= -1
            score_df.iloc[:, i] *= -1 

    # --- è² è·é‡ï¼ˆLoadingsï¼‰ã®CSVå‡ºåŠ› ---
    loadings = pd.DataFrame(components.T, index=sector_df.columns, columns=pc_cols)
    loadings.to_csv(pca_dir / "ã‚»ã‚¯ã‚¿ãƒ¼ã®è² è·é‡_ä¸€è¦§.csv", encoding="utf-8-sig")

    pca_dir = root_dir / "pca_analysis"
    pca_dir.mkdir(exist_ok=True)

    # --- å¯„ä¸ç‡ã®ä¿å­˜ã‚’è¿½åŠ  ---
    expl = pca.explained_variance_ratio_
    expl_df = pd.DataFrame(expl.reshape(1, -1), columns=pc_cols, index=["ExplainedVariance"])
    expl_df.to_csv(pca_dir / "ä¸»æˆåˆ†_å¯„ä¸ç‡.csv", encoding="utf-8-sig")

    # ã‚¹ã‚³ã‚¢æ¨ç§»ãƒ—ãƒ­ãƒƒãƒˆï¼ˆPC3ã¾ã§ï¼‰
    plt.figure(figsize=(12, 5))
    colors = ['#1f77b4', '#ff7f0e', '#2ca02c']
    for i, pc in enumerate(pc_cols[:3]):
        plt.plot(score_df.index, score_df[pc], label=f"{pc} (å¯„ä¸:{expl[i]*100:.1f}%)", color=colors[i], lw=2)
    plt.title("ä¸»æˆåˆ†ã‚¹ã‚³ã‚¢ã®æ¨ç§» (ã‚»ã‚¯ã‚¿ãƒ¼æ¨™æº–åŒ–å¾Œã®ç”Ÿå€¤)")
    
    # --- è»¸ãƒ©ãƒ™ãƒ«è¿½åŠ  ---
    plt.xlabel("æ—¥ä»˜")
    plt.ylabel("ä¸»æˆåˆ†ã‚¹ã‚³ã‚¢")
    
    plt.axhline(0, color='black', lw=1); plt.legend(loc='upper left', bbox_to_anchor=(1, 1)); plt.grid(axis='y', alpha=0.3); plt.tight_layout()
    plt.savefig(pca_dir / "PCA_ã‚¹ã‚³ã‚¢æ¨ç§»_ç”Ÿå€¤.png"); plt.close()

    # è² è·é‡ã®æ£’ã‚°ãƒ©ãƒ•ï¼ˆPC3ã¾ã§ï¼‰
    for i, pc in enumerate(pc_cols[:3]):
        plt.figure(figsize=(10, 5))
        loadings[pc].reindex(loadings[pc].abs().sort_values(ascending=False).index).head(10).plot(kind='bar', color=colors[i])
        plt.title(f"{pc} ã‚»ã‚¯ã‚¿ãƒ¼ã®è² è·é‡ (å¯„ä¸:{expl[i]*100:.1f}%)")
        
        # --- è»¸ãƒ©ãƒ™ãƒ«è¿½åŠ  ---
        plt.xlabel("ã‚»ã‚¯ã‚¿ãƒ¼")
        plt.ylabel("è² è·é‡")
        
        plt.axhline(0, color='black', lw=1); plt.xticks(rotation=45, ha='right'); plt.grid(axis='y', alpha=0.3); plt.tight_layout()
        plt.savefig(pca_dir / f"è² è·é‡_{pc}_TOP10.png"); plt.close()

    print(f"âœ… PCAåˆ†æå®Œäº†: {pca_dir}")

def plot_abs_heatmaps(full_pca_df, output_root):
    # PCã”ã¨ã«ãƒ«ãƒ¼ãƒ—ã—ã¦å¯è¦–åŒ–
    for pc in ["PC1", "PC2", "PC3"]:
        target_df = full_pca_df[full_pca_df["PC_Type"] == pc]
        if target_df.empty: continue
        
        # ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦åã‚’ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã«ã—ã¦ã€ã‚»ã‚¯ã‚¿ãƒ¼åˆ—ã®ã¿æŠ½å‡ºï¼ˆæ•°å€¤ãƒ‡ãƒ¼ã‚¿ã®ã¿ï¼‰
        # æ–‡å­—åˆ—ã‚«ãƒ©ãƒ ã‚’é™¤å¤–ã—ã¦è»¢ç½®
        plot_data = target_df.drop(columns=["PC_Type", "Window", "Explained_Variance"]).T
        plot_data.columns = target_df["Window"] # xè»¸ã‚’ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦åã«
        
        plt.figure(figsize=(14, 9))
        
        # è² è·é‡ã®çµ¶å¯¾å€¤ãªã®ã§ã€0ã‹ã‚‰ã®å¼·å¼±ãŒã¯ã£ãã‚Šã™ã‚‹ "Reds" ãªã©ã‚’æ¡ç”¨
        # vmin=0, vmax=0.5 ãªã©ã§ã‚¹ã‚±ãƒ¼ãƒ«ã‚’å›ºå®šã™ã‚‹ã¨ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦é–“ã®æ¯”è¼ƒãŒã—ã‚„ã™ããªã‚Šã¾ã™
        sns.heatmap(plot_data, 
                    cmap="Reds", 
                    annot=False, 
                    cbar_kws={'label': f'{pc} è² è·é‡ï¼ˆçµ¶å¯¾å€¤ï¼‰'},
                    vmin=0, 
                    vmax=max(0.5, plot_data.max().max())) 
        
        # å¯„ä¸ç‡ã‚’å–å¾—
        mean_var = target_df["Explained_Variance"].mean() * 100
        plt.title(f"{pc} æ§‹æˆã‚»ã‚¯ã‚¿ãƒ¼ã®è² è·é‡æ¨ç§»ï¼ˆçµ¶å¯¾å€¤ï¼‰\n[å¹³å‡å¯„ä¸ç‡: {mean_var:.1f}%]", fontsize=14)
        plt.xlabel("ãƒ†ã‚¹ãƒˆã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ (Window)", fontsize=12)
        plt.ylabel("ã‚»ã‚¯ã‚¿ãƒ¼", fontsize=12)
        
        plt.tight_layout()
        plt.savefig(output_root / f"å…¨æœŸé–“_{pc}_æ§‹é€ æ¨ç§»_çµ¶å¯¾å€¤.png")
        plt.close()

def aggregate_results(output_root):
    output_root = Path(output_root)
    all_summaries = []
    pca_abs_details = []

    # 1. å„ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã‚’å·¡å›ã—ã¦ç”Ÿãƒ‡ãƒ¼ã‚¿ã‚’åé›†
    for window_path in sorted(output_root.glob("Window_Test_*")):
        window_name = window_path.name.replace("Window_Test_", "")
        
        # ãƒ¢ãƒ‡ãƒ«æ¯”è¼ƒã‚µãƒãƒªãƒ¼
        summary_file = window_path / "ãƒ¢ãƒ‡ãƒ«æ¯”è¼ƒã‚µãƒãƒªãƒ¼.csv"
        if summary_file.exists():
            df = pd.read_csv(summary_file)
            df["Test_Window"] = window_name
            all_summaries.append(df)
            
        # PCAè² è·é‡ï¼ˆçµ¶å¯¾å€¤ï¼‰
        loadings_file = window_path / "pca_analysis" / "ã‚»ã‚¯ã‚¿ãƒ¼ã®è² è·é‡_ä¸€è¦§.csv"
        variance_file = window_path / "pca_analysis" / "ä¸»æˆåˆ†_å¯„ä¸ç‡.csv"
        if loadings_file.exists() and variance_file.exists():
            ld_df = pd.read_csv(loadings_file, index_col=0)
            vr_df = pd.read_csv(variance_file, index_col=0)
            for pc in ["PC1", "PC2", "PC3"]:
                if pc in ld_df.columns:
                    abs_row = ld_df[pc].abs().to_frame().T
                    abs_row.index = [f"{window_name}_{pc}"]
                    abs_row.insert(0, "Window", window_name)
                    abs_row.insert(1, "PC_Type", pc)
                    abs_row.insert(2, "Explained_Variance", vr_df.at["ExplainedVariance", pc])
                    pca_abs_details.append(abs_row)

    if not all_summaries:
        return

    # --- 2. ãƒ¢ãƒ‡ãƒ«è©•ä¾¡ã®è©³ç´°çµ±è¨ˆï¼ˆå¿˜ã‚Œã¦ãªã„ãƒã‚¤ãƒ³ãƒˆï¼š0é™¤å¤– & æ—¥æœ¬èªã‚«ãƒ©ãƒ ï¼‰ ---
    # ignore_index=True ã‚’è¿½åŠ ã—ã¦ã€ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã®é‡è¤‡ã‚’è§£æ¶ˆã™ã‚‹
    merged_summary = pd.concat(all_summaries, ignore_index=True)

    plot_final_boxplots(merged_summary, output_root)
    
    # ç®±ã²ã’å›³ã‚’ç”Ÿãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ä½œæˆ
    # plot_model_boxplots(merged_summary, output_root)
    
    target_cols = ["è¨“ç·´RMSE", "äºˆæ¸¬RMSE", "RMSEæ¯”", "AIC", "æœ€å¤§å›ºæœ‰å€¤"]
    stats_list = []
    for col in target_cols:
        if col in merged_summary.columns:
            temp_series = merged_summary.copy()
            if col != "AIC": # AICä»¥å¤–ã¯0ã‚’å¤–ã™
                temp_series[col] = temp_series[col].replace(0, np.nan)
            
            res = temp_series.groupby("ãƒ¢ãƒ‡ãƒ«æ§‹æˆ")[col].agg([
                (f"{col}_å¹³å‡", "mean"),
                (f"{col}_æ¨™æº–åå·®", "std"),
                (f"{col}_æœ€å¤§", "max"),
                (f"{col}_æœ€å°", "min")
            ])
            stats_list.append(res)
    
    model_perf_detail = pd.concat(stats_list, axis=1)
    model_perf_detail["æœ‰åŠ¹è©¦è¡Œå›æ•°"] = merged_summary.groupby("ãƒ¢ãƒ‡ãƒ«æ§‹æˆ")["äºˆæ¸¬RMSE"].apply(lambda x: (x != 0).sum())
    model_perf_detail = model_perf_detail.round(4)
    model_perf_detail.to_csv(output_root / "å…¨ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦é›†è¨ˆ_ãƒ¢ãƒ‡ãƒ«è©•ä¾¡_è©³ç´°ç‰ˆ.csv", encoding="utf-8-sig")

    # --- 3. PCAæ§‹é€ ã®é›†è¨ˆã¨ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ï¼ˆã“ã“ã‚‚å¿˜ã‚Œã¦ã¾ã›ã‚“ï¼ï¼‰ ---
    if pca_abs_details:
        full_pca_df = pd.concat(pca_abs_details)
        full_pca_df.to_csv(output_root / "å…¨ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦é›†è¨ˆ_PCAæ§‹é€ _çµ¶å¯¾å€¤è©³ç´°.csv", encoding="utf-8-sig")
        # çµ¶å¯¾å€¤ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ã‚’ä¿å­˜
        plot_abs_heatmaps(full_pca_df, output_root)

    print(f"âœ… ã™ã¹ã¦ã®é›†è¨ˆãƒ»ç”»åƒä¿å­˜ï¼ˆãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ã€ç®±ã²ã’å›³ã€çµ±è¨ˆè©³ç´°ï¼‰ãŒå®Œäº†ã—ã¾ã—ãŸã€‚")

def plot_custom_error_boxes(merged_summary, output_root):
    """
    ã€ç‰¹è£½ãƒ»æ¥µç°¡ç‰ˆã€‘
    ç®±ã®ä¸Šä¸‹ç«¯ã‚’ã€Œå¹³å‡ Â± æ¨™æº–åå·®ã€ã«ã—ã€æœ€å¤§ãƒ»æœ€å°ã‚’ãƒ’ã‚²ã§è¡¨ç¾ã€‚ç”Ÿãƒ‡ãƒ¼ã‚¿ç‚¹ã¯å®Œå…¨æ’é™¤ã€‚
    """
    output_root = Path(output_root)
    # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹é‡è¤‡å¯¾ç­–
    plot_df_base = merged_summary.copy().reset_index(drop=True)
    targets = ["è¨“ç·´RMSE", "äºˆæ¸¬RMSE", "RMSEæ¯”", "AIC", "æœ€å¤§å›ºæœ‰å€¤"]

    for col in targets:
        if col not in plot_df_base.columns: continue
        
        plt.figure(figsize=(12, 7))
        # 0é™¤å¤–ï¼ˆAICä»¥å¤–ï¼‰
        plot_data = plot_df_base[plot_df_base[col] != 0].copy() if col != "AIC" else plot_df_base.copy()
        
        # ãƒ¢ãƒ‡ãƒ«ã”ã¨ã®çµ±è¨ˆé‡ã‚’ç®—å‡º
        stats = plot_data.groupby("ãƒ¢ãƒ‡ãƒ«æ§‹æˆ")[col].agg(["mean", "std", "min", "max"]).sort_values("mean")
        x_names = stats.index
        x_coords = np.arange(len(x_names))

        # 1. ã€Œå¹³å‡ Â± æ¨™æº–åå·®ã€ã®ç®±ã‚’æç”»
        # æ°´è‰²ã®ç®±ãŒã€Œæ¨™æº–åå·®ã€ã®åºƒãŒã‚Šã‚’è¡¨ã™
        plt.bar(x_coords, (stats["std"] * 2), bottom=(stats["mean"] - stats["std"]),
                width=0.5, color='skyblue', alpha=0.6, label='å¹³å‡ Â± 1æ¨™æº–åå·®', edgecolor='blue', lw=1.5)

        # 2. å¹³å‡å€¤ã«å¤ªã„èµ¤ç·šã‚’å¼•ã
        plt.hlines(stats["mean"], x_coords - 0.25, x_coords + 0.25, color='red', lw=3, label='å¹³å‡å€¤')

        # 3. æœ€å¤§ãƒ»æœ€å°ã‚’ã€Œãƒ’ã‚²ã€ã¨ã—ã¦æç”»
        # ã“ã‚Œã§ã€æœ€æ‚ªã®ã‚±ãƒ¼ã‚¹ï¼ˆ150è¶…ãˆãªã©ï¼‰ãŒã©ã“ã¾ã§ä¼¸ã³ãŸã‹åˆ†ã‹ã‚Šã¾ã™
        plt.vlines(x_coords, stats["min"], stats["max"], color='black', lw=1.2, ls='-')
        # ãƒ’ã‚²ã®ä¸Šä¸‹ã®æ¨ªæ£’
        plt.scatter(x_coords, stats["min"], marker='_', color='black', s=200, lw=2)
        plt.scatter(x_coords, stats["max"], marker='_', color='black', s=200, lw=2)

        plt.xticks(x_coords, x_names, rotation=45, ha='right')
        plt.ylabel(col)
        plt.title(f"{col} ã®çµ±è¨ˆåˆ†å¸ƒ\n[æ°´è‰²ç®±: å¹³å‡Â±æ¨™æº–åå·®, èµ¤ç·š: å¹³å‡, ãƒ’ã‚²: æœ€å¤§ãƒ»æœ€å°]")
        plt.grid(axis='y', alpha=0.3, ls=':')
        plt.legend(loc='upper left')
        plt.tight_layout()
        
        # ä¿å­˜
        plt.savefig(output_root / f"å…¨æœŸé–“_çµ±è¨ˆç®±_{col}.png", dpi=300)
        plt.close()

    print(f"ğŸ“Š çµ±è¨ˆç®±ã‚°ãƒ©ãƒ•ï¼ˆäºˆæ¸¬RMSE, AICãªã©å…¨5ç¨®ï¼‰ã‚’ä¿å­˜ã—ã¾ã—ãŸã€‚ç‚¹ã¯æ¶ˆã—ã¾ã—ãŸã€‚")

def plot_model_boxplots(merged_summary, output_root):
    """
    å…¨æŒ‡æ¨™ã«å¯¾ã—ã¦ã€ç®±ã²ã’å›³(åˆ†å¸ƒ)ã®ä¸Šã«å¹³å‡ãƒ»æ¨™æº–åå·®(ã‚¨ãƒ©ãƒ¼ãƒãƒ¼)ã‚’é‡ã­ã¦å¯è¦–åŒ–
    """
    output_root = Path(output_root)
    # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹é‡è¤‡ã‚¨ãƒ©ãƒ¼å¯¾ç­–
    plot_df_base = merged_summary.copy().reset_index(drop=True)
    
    # å…¨æŒ‡æ¨™ã‚’ãƒ«ãƒ¼ãƒ—ã§å›ã™
    targets = ["è¨“ç·´RMSE", "äºˆæ¸¬RMSE", "RMSEæ¯”", "AIC", "æœ€å¤§å›ºæœ‰å€¤"]
    
    for col in targets:
        if col not in plot_df_base.columns:
            continue
            
        plt.figure(figsize=(14, 8))
        
        # 0é™¤å¤–ï¼ˆAICä»¥å¤–ï¼‰
        if col != "AIC":
            plot_data = plot_df_base[plot_df_base[col] != 0].copy()
        else:
            plot_data = plot_df_base.copy()
            
        if plot_data.empty: continue

        # å¹³å‡å€¤ãŒä½ã„é †ï¼ˆå„ªç§€ãªé †ï¼‰ã«å·¦ã‹ã‚‰ä¸¦ã¹ã‚‹
        order = plot_data.groupby("ãƒ¢ãƒ‡ãƒ«æ§‹æˆ")[col].mean().sort_values().index
        
        # 1. ç®±ã²ã’å›³ï¼ˆåˆ†å¸ƒãƒ»ä¸­å¤®å€¤ãƒ»å››åˆ†ä½ã‚’è¡¨ç¤ºï¼‰
        # alphaã‚’ä¸‹ã’ã¦ã€ä¸Šã«é‡ã­ã‚‹ã‚¨ãƒ©ãƒ¼ãƒãƒ¼ã‚’è¦‹ã‚„ã™ãã™ã‚‹
        sns.boxplot(data=plot_data, x="ãƒ¢ãƒ‡ãƒ«æ§‹æˆ", y=col, order=order, 
                    palette="Pastel1", width=0.6, boxprops=dict(alpha=0.4))
        
        # 2. å¹³å‡ãƒ»æ¨™æº–åå·®ã®ã‚¨ãƒ©ãƒ¼ãƒãƒ¼ï¼ˆã”è¦æœ›ã®ã€Œå¹³å‡ã€œæ¨™æº–åå·®ã€ã®å¸¯ï¼‰
        # ci="sd" (ã¾ãŸã¯ errorbar="sd") ã§æ¨™æº–åå·®ã‚’è¡¨ç¤º
        sns.pointplot(data=plot_data, x="ãƒ¢ãƒ‡ãƒ«æ§‹æˆ", y=col, order=order,
                      join=False, color="red", marker="D", scale=0.8, 
                      errorbar="sd", capsize=.15, label="å¹³å‡ Â± æ¨™æº–åå·®")
        
        # 3. ç”Ÿãƒ‡ãƒ¼ã‚¿ç‚¹ï¼ˆå®Ÿéš›ã®å…¨ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã®å€¤ã‚’ãƒ‰ãƒƒãƒˆã§è¡¨ç¤ºï¼‰
        sns.stripplot(data=plot_data, x="ãƒ¢ãƒ‡ãƒ«æ§‹æˆ", y=col, order=order, 
                      color="black", alpha=0.2, jitter=True)
        
        plt.xticks(rotation=45, ha='right')
        plt.title(f"ãƒ¢ãƒ‡ãƒ«æ§‹æˆåˆ¥ {col} ã®è©³ç´°åˆ†å¸ƒ (å…¨ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦)\n[ç®±:ä¸­å¤®å€¤, â—†:å¹³å‡, èµ¤ç·š:Â±1æ¨™æº–åå·®]", fontsize=14)
        plt.grid(axis='y', linestyle='--', alpha=0.4)
        
        # å‡¡ä¾‹ã‚’è¡¨ç¤º
        plt.legend(loc='upper left')

        plt.tight_layout()
        
        # æŒ‡æ¨™åã‚’å«ã‚ã¦ä¿å­˜
        save_path = output_root / f"å…¨æœŸé–“_è©³ç´°ç®±ã²ã’_{col}.png"
        plt.savefig(save_path, dpi=300)
        plt.close()

    print(f"ğŸ“Š å…¨æŒ‡æ¨™ã®ç®±ã²ã’å›³ï¼ˆã‚¨ãƒ©ãƒ¼ãƒãƒ¼ä»˜ãï¼‰ã‚’ä¿å­˜ã—ã¾ã—ãŸã€‚")

def plot_final_boxplots(merged_summary, output_root):
    """
    ã‚ãªãŸãŒã€ãˆãˆæ„Ÿã˜ã€ã¨è¨€ã£ãŸã€è‰²ä»˜ãã®ç®±ã²ã’å›³ ï¼‹ çµ±è¨ˆé‡
    """
    output_root = Path(output_root)
    plot_df_base = merged_summary.copy().reset_index(drop=True)
    
    targets = ["è¨“ç·´RMSE", "äºˆæ¸¬RMSE", "RMSEæ¯”", "AIC", "æœ€å¤§å›ºæœ‰å€¤"]
    
    for col in targets:
        if col not in plot_df_base.columns: continue
            
        plt.figure(figsize=(14, 8))
        
        # 0é™¤å¤–ï¼ˆAICä»¥å¤–ï¼‰
        plot_data = plot_df_base[plot_df_base[col] != 0].copy() if col != "AIC" else plot_df_base.copy()
        if plot_data.empty: continue

        # å¹³å‡å€¤ãŒä½ã„é †ã«ã‚½ãƒ¼ãƒˆã—ã¦ä¸¦ã¹ã‚‹
        order = plot_data.groupby("ãƒ¢ãƒ‡ãƒ«æ§‹æˆ")[col].mean().sort_values().index
        
        # 1. ã€ãƒ¡ã‚¤ãƒ³ã€‘è‰²ä»˜ãã®ç®±ã²ã’å›³ï¼ˆã“ã‚ŒãŒã€ãˆãˆæ„Ÿã˜ã€ã®æ­£ä½“ï¼‰
        sns.boxplot(data=plot_data, x="ãƒ¢ãƒ‡ãƒ«æ§‹æˆ", y=col, order=order, 
                    palette="Set3", width=0.6, boxprops=dict(alpha=0.7))
        
        # 2. å¹³å‡å€¤(â—†)ã¨æ¨™æº–åå·®(èµ¤ç·š)ã‚’é‡ã­ã‚‹
        sns.pointplot(data=plot_data, x="ãƒ¢ãƒ‡ãƒ«æ§‹æˆ", y=col, order=order,
                      join=False, color="red", marker="D", scale=0.7, 
                      errorbar="sd", capsize=.15, label="å¹³å‡ Â± æ¨™æº–åå·®")
        
        # 3. ç”Ÿãƒ‡ãƒ¼ã‚¿ï¼ˆè–„ã„ç‚¹ï¼‰ã¯ãƒã‚¤ã‚ºã«ãªã‚‹ã®ã§ã€ã“ã“ã§ã¯é™¤å¤–ã‹æ¥µè–„ã«
        # sns.stripplot(data=plot_data, x="ãƒ¢ãƒ‡ãƒ«æ§‹æˆ", y=col, order=order, color="black", alpha=0.1, jitter=True)

        plt.xticks(rotation=45, ha='right')
        plt.title(f"{col} ã®åˆ†å¸ƒã¨çµ±è¨ˆæŒ‡æ¨™ (å…¨ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦)\n[ç®±:åˆ†å¸ƒ, â—†:å¹³å‡, èµ¤ç¸¦ç·š:æ¨™æº–åå·®]", fontsize=14)
        plt.grid(axis='y', linestyle='--', alpha=0.4)
        plt.legend(loc='upper left')
        plt.tight_layout()
        
        plt.savefig(output_root / f"å…¨æœŸé–“_ãˆãˆæ„Ÿã˜ç®±ã²ã’_{col}.png", dpi=300)
        plt.close()

def visualize_model_performance(csv_path):
    # CSVï¼ˆè©³ç´°é›†è¨ˆç‰ˆï¼‰ã®èª­ã¿è¾¼ã¿
    df = pd.read_csv(csv_path, index_col=0)
    output_dir = Path(csv_path).parent
    plt.style.use('ggplot')

    # å‡ºåŠ›ã—ãŸã„æŒ‡æ¨™ã®ãƒªã‚¹ãƒˆ
    targets = ["äºˆæ¸¬RMSE", "AIC", "è¨“ç·´RMSE", "æœ€å¤§å›ºæœ‰å€¤", "RMSEæ¯”"]

    for col in targets:
        avg_col = f"{col}_å¹³å‡"
        std_col = f"{col}_æ¨™æº–åå·®"
        
        if avg_col not in df.columns:
            continue

        # --- 1. æ£’ã‚°ãƒ©ãƒ• ï¼‹ ã‚¨ãƒ©ãƒ¼ãƒãƒ¼ï¼ˆå¹³å‡ã¨æ¨™æº–åå·®ï¼‰ ---
        plt.figure(figsize=(12, 7))
        # å¹³å‡å€¤ãŒä½ã„é †ï¼ˆè‰¯ã„é †ï¼‰ã«ä¸¦ã¹æ›¿ãˆ
        df_sorted = df.sort_values(avg_col)
        
        # ã‚ãªãŸãŒã€Œã„ã„æ„Ÿã˜ã€ã¨è¨€ã£ã¦ãã‚ŒãŸã‚¹ã‚¿ã‚¤ãƒ«
        plt.bar(df_sorted.index, df_sorted[avg_col], 
                yerr=df_sorted[std_col], 
                capsize=5, color='skyblue', edgecolor='navy', alpha=0.7)
        
        plt.xticks(rotation=45, ha='right')
        plt.ylabel(f"{col} (å¹³å‡)")
        plt.title(f"ãƒ¢ãƒ‡ãƒ«æ§‹æˆåˆ¥ {col} æ¯”è¼ƒ\n(ã‚¨ãƒ©ãƒ¼ãƒãƒ¼ã¯æ¨™æº–åå·®ã‚’è¡¨ç¤º)")
        plt.grid(axis='y', linestyle='--', alpha=0.7)
        plt.tight_layout()
        
        # æŒ‡æ¨™åã‚’ã¤ã‘ã¦ä¿å­˜
        plt.savefig(output_dir / f"å…¨æœŸé–“_æ¯”è¼ƒ_{col}.png", dpi=300)
        plt.close()

    # --- 2. AIC vs äºˆæ¸¬RMSE ã®æ•£å¸ƒå›³ï¼ˆã“ã‚Œã¯1æšã ã‘ä½œæˆï¼‰ ---
    if "AIC_å¹³å‡" in df.columns and "äºˆæ¸¬RMSE_å¹³å‡" in df.columns:
        plt.figure(figsize=(10, 7))
        sns.scatterplot(data=df, x="AIC_å¹³å‡", y="äºˆæ¸¬RMSE_å¹³å‡", 
                        size="äºˆæ¸¬RMSE_æ¨™æº–åå·®", hue=df.index, 
                        sizes=(100, 1000), alpha=0.6)
        
        for i, txt in enumerate(df.index):
            plt.annotate(txt, (df["AIC_å¹³å‡"].iloc[i], df["äºˆæ¸¬RMSE_å¹³å‡"].iloc[i]), 
                         xytext=(5, 5), textcoords='offset points', fontsize=8)
            
        plt.title("ãƒ¢ãƒ‡ãƒ«ã®è¤‡é›‘ã•(AIC) vs äºˆæ¸¬ç²¾åº¦(RMSE)")
        plt.grid(True, alpha=0.3)
        plt.tight_layout()
        plt.savefig(output_dir / "å…¨æœŸé–“_AIC_vs_RMSE_åˆ†å¸ƒ.png", dpi=300)
        plt.close()

    print(f"ğŸ’¾ ã‚°ãƒ©ãƒ•ï¼ˆæ£’ã‚°ãƒ©ãƒ•5ç¨® ï¼‹ æ•£å¸ƒå›³1ç¨®ï¼‰ã‚’ {output_dir} ã«ä¿å­˜ã—ã¾ã—ãŸã€‚")

# =========================================================
# 3. ãƒ¡ã‚¤ãƒ³å‡¦ç†
# =========================================================
def main():
    # ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ã¨å‰å‡¦ç†ï¼ˆã“ã“ã¯å…±é€šï¼‰
    df_raw = pd.read_csv(CONFIG["data_path"], index_col=0, parse_dates=True).sort_index()
    sector_df, macro_df, common_idx, meta = prepare_aligned(df_raw)
    
    # --- Moving Window è¨­å®š ---
    test_len = 4
    n_total = len(common_idx)
    
    # ãƒ†ã‚¹ãƒˆæœŸé–“ã‚’1æœŸãšã¤ãšã‚‰ã—ã¦å…¨çµ„ã¿åˆã‚ã›ã‚’å®Ÿè¡Œ
    for i in range(n_total - test_len + 1):
        # ãƒ†ã‚¹ãƒˆæœŸé–“ã¨è¨“ç·´æœŸé–“ï¼ˆãƒ†ã‚¹ãƒˆä»¥å¤–ã™ã¹ã¦ï¼‰ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ä½œæˆ
        te_idx_list = np.arange(i, i + test_len)
        tr_idx_list = np.setdiff1d(np.arange(n_total), te_idx_list)
        
        # ãƒ•ã‚©ãƒ«ãƒ€åç”¨ã®æ—¥ä»˜å–å¾—
        d_start = common_idx[te_idx_list[0]]
        d_end = common_idx[te_idx_list[-1]]
        
        # ãƒ«ãƒ¼ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªè¨­å®šï¼ˆã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã”ã¨ã«ä½œæˆï¼‰
        root_dir = Path(CONFIG["output_dir"]) / f"Window_Test_{d_start:%Y%m%d}_{d_end:%Y%m%d}"
        root_dir.mkdir(parents=True, exist_ok=True)
        
        print(f"â–¶ï¸ å®Ÿè¡Œä¸­: {root_dir.name}")

        # 1. PCA: è¨“ç·´ãƒ‡ãƒ¼ã‚¿(tr_idx_list)ã§Fitã—ã€å…¨æœŸé–“ã‚’Transform
        sc_pca = StandardScaler()
        X_tr_pca = sc_pca.fit_transform(sector_df.iloc[tr_idx_list])
        pca_temp = PCA().fit(X_tr_pca)
        n_pcs = max(3, np.argmax(np.cumsum(pca_temp.explained_variance_ratio_) >= 0.90) + 1)
        
        pca = PCA(n_components=n_pcs).fit(X_tr_pca)
        pc_cols_orig = [f"PC{k+1}" for k in range(n_pcs)]
        
        # 2. å…¨æœŸé–“ã®PCå·®åˆ†ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆï¼ˆãƒªãƒ¼ã‚¯é˜²æ­¢ã®ãŸã‚PCAã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã¯ç¶­æŒï¼‰
        # pca_no_leakç›¸å½“ã®å‡¦ç†ã‚’Windowç”¨ã«èª¿æ•´
        full_pcs = pca.transform(sc_pca.transform(sector_df))
        pc_diff_all = pd.DataFrame(full_pcs, index=sector_df.index).diff().dropna()
        pc_cols_diff = [f"PC{k+1}_DIFF" for k in range(3)]
        pc_diff_all = pc_diff_all.iloc[:, :3]
        pc_diff_all.columns = pc_cols_diff

        # --- å…ƒã®åˆ†æãƒ¬ãƒãƒ¼ãƒˆ(analyze_pca_details)å®Ÿè¡Œ ---
        # å¼•æ•°ã¯Windowã«åˆã‚ã›ã¦èª¿æ•´
        analyze_pca_details(pca, sector_df, pc_cols_orig, root_dir, tr_idx_list[0], tr_idx_list[-1], test_len)
        
        # ãƒã‚¯ãƒ­åŒæœŸ
        m_df_win = macro_df.loc[pc_diff_all.index]
        combinations = [[]] + [list(c) for r in range(1, 4) for c in itertools.combinations(pc_cols_diff, r)]
        summary_list = []

        for combo in combinations:
            m_name_display = ", ".join(combo) if combo else "ãƒã‚¯ãƒ­ã®ã¿"
            sub_dir = root_dir / ("_".join(combo) if combo else "BASE_VAR_ONLY")
            sub_dir.mkdir(parents=True, exist_ok=True)
            
            # --- è¨“ç·´ã¨ãƒ†ã‚¹ãƒˆã®åˆ‡ã‚Šå‡ºã— ---
            win_idx = m_df_win.index
            tr_pre_dates = common_idx[tr_idx_list[tr_idx_list < te_idx_list[0]]]
            tr_post_dates = common_idx[tr_idx_list[tr_idx_list > te_idx_list[-1]]]
            te_dates = common_idx[te_idx_list]
            
            # 1. éå»å´ã®è¨“ç·´ãƒ‡ãƒ¼ã‚¿
            tr_pre = pd.concat([m_df_win.loc[win_idx.isin(tr_pre_dates)], 
                                pc_diff_all.loc[win_idx.isin(tr_pre_dates), combo]], axis=1)
            
            # 2. æœªæ¥å´ã®è¨“ç·´ãƒ‡ãƒ¼ã‚¿
            tr_post = pd.concat([m_df_win.loc[win_idx.isin(tr_post_dates)], 
                                 pc_diff_all.loc[win_idx.isin(tr_post_dates), combo]], axis=1)
            
            # ã€é‡è¦ã€‘æœªæ¥å´ãƒ‡ãƒ¼ã‚¿ã®å…ˆé ­1è¡Œã‚’NaNã«ã™ã‚‹ï¼ˆãƒ©ã‚°è¨ˆç®—ã§éå»å´ã¨ç¹‹ãŒã‚‹ã®ã‚’é˜²ããŸã‚ï¼‰
            if not tr_post.empty:
                tr_post.iloc[0, :] = np.nan

            # 3. è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã®çµåˆï¼ˆä¸­æŠœãã•ã‚ŒãŸç®‡æ‰€ã«NaNã®å£ãŒã§ãã‚‹ï¼‰
            tr_raw = pd.concat([tr_pre, tr_post])
            te_raw = pd.concat([m_df_win.loc[win_idx.isin(te_dates)], 
                                pc_diff_all.loc[win_idx.isin(te_dates), combo]], axis=1)

            means, stds = tr_raw.mean(), tr_raw.std(ddof=0).replace(0, 1.0)
            tr_s, te_s = (tr_raw - means) / stds, (te_raw - means) / stds
            m_cols, m_dim = list(macro_df.columns), len(macro_df.columns)
            
            # ãƒ¢ãƒ‡ãƒ«æ¨å®š
            Y_tr, X_tr = make_design(tr_s[m_cols], tr_s[combo] if combo else None, CONFIG["p_lag"])
            Beta = np.linalg.solve(X_tr.T @ X_tr + CONFIG["ridge"] * np.eye(X_tr.shape[1]), X_tr.T @ Y_tr)
            
            # --- æ—¢å­˜ã®ãƒ¢ãƒ‡ãƒ«æ¨å®šç›´å¾Œã‹ã‚‰ ---
            # æŒ‡æ¨™è¨ˆç®—
            tr_resid = Y_tr - X_tr @ Beta
            n_obs = len(Y_tr)
            tr_rmse = np.sqrt(np.mean(tr_resid**2))
            
            Y_te, X_te = make_design(te_s[m_cols], te_s[combo] if combo else None, CONFIG["p_lag"])
            te_rmse = np.sqrt(np.mean((Y_te - X_te @ Beta)**2)) if len(Y_te) > 0 else np.nan
            
            # --- AICè¨ˆç®—ãƒ­ã‚¸ãƒƒã‚¯ã®å¼·åŒ–ç‰ˆ ---
            sigma_matrix = (tr_resid.T @ tr_resid) / n_obs
            sign, logdet = np.linalg.slogdet(sigma_matrix)
            
            if sign > 0:
                # é€šå¸¸ã®è¨ˆç®—
                aic_val = n_obs * logdet + 2 * Beta.size
            else:
                # è¡Œåˆ—å¼ãŒæ­£å¸¸ã«è¨ˆç®—ã§ããªã„å ´åˆã®ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—
                # æ­£ã®å›ºæœ‰å€¤ã®ã¿ã‚’æŠ½å‡ºã—ã¦å¯¾æ•°å’Œã‚’ã¨ã‚‹
                eigs = np.linalg.eigvalsh(sigma_matrix)
                valid_eigs = eigs[eigs > 1e-15] # ã»ã¼ã‚¼ãƒ­ä»¥ä¸Šã®å›ºæœ‰å€¤ã®ã¿
                if len(valid_eigs) > 0:
                    aic_val = n_obs * np.sum(np.log(valid_eigs)) + 2 * Beta.size
                else:
                    aic_val = np.nan
            # -------------------------------

            A1 = Beta[1:1+m_dim, :].T
            max_eig_abs = np.max(np.abs(np.linalg.eigvals(A1)))

            summary_list.append({
                "ãƒ¢ãƒ‡ãƒ«æ§‹æˆ": m_name_display,
                "è¨“ç·´RMSE": round(tr_rmse, 4),
                "äºˆæ¸¬RMSE": round(te_rmse, 4) if not np.isnan(te_rmse) else np.nan,
                "RMSEæ¯”": round(te_rmse / tr_rmse, 2) if tr_rmse > 0 and not np.isnan(te_rmse) else np.nan,
                "AIC": round(aic_val, 2) if not np.isnan(aic_val) else np.nan,
                "æœ€å¤§å›ºæœ‰å€¤": round(max_eig_abs, 3)
            })

            # --- å…ƒã®IRFãƒ—ãƒ­ãƒƒãƒˆ(å¤‰æ›´ãªã—) ---
            if CONFIG["do_irf"] and combo:
                B = Beta[1+m_dim:, :].T
                for j, pc_label in enumerate(combo):
                    pc_folder = sub_dir / f"Shock_{pc_label}"; pc_folder.mkdir(parents=True, exist_ok=True)
                    impact = np.zeros((13, m_dim)); impact[1] = B[:, j]
                    for h in range(2, 13): impact[h] = A1 @ impact[h-1]
                    for i_m, m_col in enumerate(m_cols):
                        orig_m, meth_m = meta[m_col]["orig"], meta[m_col]["method"]
                        base = BASE_LEVELS.get(orig_m, 100); imp_raw = impact[:, i_m] * stds[m_col]
                        vals = [base]
                        for s in range(1, 13): vals.append(vals[-1] * np.exp(imp_raw[s]) if meth_m == "LOGDIFF" else vals[-1] + imp_raw[s])
                        plt.figure(figsize=(6, 3.5))
                        ax = plt.gca()
                        ax.yaxis.get_major_formatter().set_useOffset(False)
                        ax.yaxis.get_major_formatter().set_scientific(False)
                        plt.plot(range(13), vals, color='k', lw=1)
                        plt.scatter(range(13), vals, marker='o', s=15, color='k', zorder=2)
                        plt.scatter(1, vals[1], facecolors='none', edgecolors='k', marker='o', s=100, lw=1, zorder=3)
                        plt.axvline(x=1, color='k', ls='--', lw=0.7, alpha=0.6)
                        plt.axhline(base, color='gray', ls=':', lw=0.8)
                        plt.title(f"{pc_label} â†’ {orig_m}")
                        plt.grid(alpha=0.15); plt.tight_layout()
                        plt.savefig(pc_folder / f"{orig_m}_å¿œç­”.png"); plt.close()

        # ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã”ã¨ã®ã‚µãƒãƒªãƒ¼ä¿å­˜
        pd.DataFrame(summary_list).sort_values("AIC").to_csv(root_dir / "ãƒ¢ãƒ‡ãƒ«æ¯”è¼ƒã‚µãƒãƒªãƒ¼.csv", index=False, encoding="utf-8-sig")

    # --- å®Ÿè¡Œéƒ¨åˆ† ---
    # aggregate_results ã‚’å®Ÿè¡Œï¼ˆã“ã‚Œã§ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ã¨è©³ç´°CSVãŒã§ãã‚‹ï¼‰
    aggregate_results(CONFIG["output_dir"])

    # ãƒ¢ãƒ‡ãƒ«è©•ä¾¡ã®å¯è¦–åŒ–ã‚°ãƒ©ãƒ•ã‚’ç”Ÿæˆ
    output_folder = Path(CONFIG["output_dir"])
    csv_file = output_folder / "å…¨ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦é›†è¨ˆ_ãƒ¢ãƒ‡ãƒ«è©•ä¾¡_è©³ç´°ç‰ˆ.csv"
    
    if csv_file.exists():
        visualize_model_performance(csv_file)
    
    print(f"âœ… å…¨å·¥ç¨‹å®Œäº†ã€‚ç”»åƒã¨CSVã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")

if __name__ == "__main__":
    main()