import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import matplotlib as mpl
from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA
from pathlib import Path
import itertools
import warnings
import seaborn as sns

warnings.simplefilter("ignore")

# =========================================================
# 1. è¨­å®šãƒ»å®šæ•°ï¼ˆâ€»ã“ã“ã¯è§¦ã‚‰ãšãã®ã¾ã¾ï¼‰
# =========================================================
CONFIG = {
    "data_path": "./data/all_q_merged.csv",
    "output_dir": "./output_pca_final",
    "train_range": ("2015-01-01", "2016-06-30"),
    "test_steps": 1,
    "pc_max": 3,
    "p_lag": 1,
    "ridge": 1.0,
    "do_irf": True,
}

BASE_LEVELS = {
    "GDP": 500000,
    "NIKKEI": 20000,
    "USD_JPY": 110,
    "UNEMP_RATE": 3.0,
    "JGB_1Y": 0.1,
    "JGB_2Y": 0.2,
    "JGB_3Y": 0.3,
    "CPI": 100,
}
TARGET_MACRO = list(BASE_LEVELS.keys())

SECTOR_COLS = [
    "RET_FOODS",
    "RET_ENERGY_RESOURCES",
    "RET_CONSTRUCTION_MATERIALS",
    "RET_RAW_MAT_CHEM",
    "RET_PHARMACEUTICAL",
    "RET_AUTOMOBILES_TRANSP_EQUIP",
    "RET_STEEL_NONFERROUS",
    "RET_MACHINERY",
    "RET_ELEC_APPLIANCES_PRECISION",
    "RET_IT_SERV_OTHERS",
    "RET_ELECTRIC_POWER_GAS",
    "RET_TRANSPORT_LOGISTICS",
    "RET_COMMERCIAL_WHOLESALE",
    "RET_RETAIL_TRADE",
    "RET_BANKS",
    "RET_FIN_EX_BANKS",
    "RET_REAL_ESTATE",
    "RET_TEST",
]

mpl.rcParams["axes.unicode_minus"] = False
plt.rcParams["font.family"] = ["Hiragino Sans"]


# =========================================================
# 2. å‰å‡¦ç†ï¼ˆâ€»çµæœåŒä¸€ï¼šä¸­èº«ã¯åŒã˜å‡¦ç†ï¼‰
# =========================================================
def smart_transform(series: pd.Series, name: str):
    if (series <= 0).any() or ("JGB" in name) or ("UNEMP" in name):
        return series.diff(), "DIFF"
    return np.log(series).diff(), "LOGDIFF"


def prepare_aligned(df_raw: pd.DataFrame):
    # macro: å¤‰æ›ã—ã¦æ•´å½¢
    m_work = pd.DataFrame(index=df_raw.index)
    meta = {}
    for col in TARGET_MACRO:
        if col in df_raw.columns:
            ts, method = smart_transform(df_raw[col], col)
            m_work[f"{col}_{method}"] = ts
            meta[f"{col}_{method}"] = {"orig": col, "method": method}
    m_df = m_work.dropna()

    # sector: ãã®ã¾ã¾ã®ä»•æ§˜ï¼ˆinterpolate + diff/dropnaã®æ¡ä»¶ï¼‰
    s_raw = df_raw[[c for c in SECTOR_COLS if c in df_raw.columns]].interpolate(
        limit_direction="both"
    )
    s_diff = (
        s_raw.dropna()
        if all(c.startswith("RET_") for c in s_raw.columns)
        else s_raw.diff().dropna()
    )

    # common index
    common = s_diff.index.intersection(m_df.index)
    return s_diff.loc[common], m_df.loc[common], common, meta


# =========================================================
# 3. åŸºæœ¬è¨ˆç®—é–¢æ•°ï¼ˆâ€»ä½¿ã£ã¦ã‚‹ãƒ­ã‚¸ãƒƒã‚¯ã¯å¤‰ãˆãªã„ï¼‰
# =========================================================
def make_design(endog: pd.DataFrame, exog: pd.DataFrame | None, p: int):
    Y = endog.values
    X_parts = [np.ones((len(endog), 1))]
    for lag in range(1, p + 1):
        X_parts.append(endog.shift(lag).values)
    if exog is not None and not exog.empty:
        X_parts.append(exog.values)

    X = np.concatenate(X_parts, axis=1)
    valid = ~np.isnan(X).any(axis=1) & ~np.isnan(Y).any(axis=1)
    return Y[valid], X[valid]


# =========================================================
# 4. PCAãƒ¬ãƒãƒ¼ãƒˆï¼ˆâ€»ä¿å­˜ãƒ•ã‚¡ã‚¤ãƒ«åãƒ»å†…å®¹ç¶­æŒï¼‰
# =========================================================
def analyze_pca_details(
    pca: PCA,
    sector_df: pd.DataFrame,
    pc_cols: list[str],
    root_dir: Path,
    t_start: int,
    t_end: int,
    t_size: int,
):
    """PCAåˆ†æï¼šæ¨™æº–åŒ–ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ã®ç”Ÿã‚¹ã‚³ã‚¢ç®—å‡ºãƒ»ãƒ—ãƒ­ãƒƒãƒˆãƒ»è² è·é‡CSVå‡ºåŠ›"""

    pca_dir = root_dir / "pca_analysis"
    pca_dir.mkdir(exist_ok=True)

    # è¨“ç·´+ãƒ†ã‚¹ãƒˆæœŸé–“ã®ãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡ºã—ã¦æ¨™æº–åŒ–
    X_target = sector_df.iloc[t_start : t_end + t_size]
    sc = StandardScaler()
    sc.fit(sector_df.iloc[t_start:t_end])
    X_scaled = sc.transform(X_target)

    # ä¸»æˆåˆ†ã‚¹ã‚³ã‚¢
    scores = pca.transform(X_scaled)
    score_df = pd.DataFrame(scores, index=X_target.index, columns=pc_cols)
    score_df.to_csv(pca_dir / "ä¸»æˆåˆ†ã‚¹ã‚³ã‚¢_ç”Ÿãƒ‡ãƒ¼ã‚¿.csv", encoding="utf-8-sig")

    expl = pca.explained_variance_ratio_
    components = pca.components_.copy()

    # ç¬¦å·åè»¢ï¼ˆå…ƒãƒ­ã‚¸ãƒƒã‚¯ï¼‰
    for i in range(components.shape[0]):
        if np.mean(components[i]) < 0:
            components[i] *= -1
            score_df.iloc[:, i] *= -1

    # è² è·é‡
    loadings = pd.DataFrame(components.T, index=sector_df.columns, columns=pc_cols)
    loadings.to_csv(pca_dir / "ã‚»ã‚¯ã‚¿ãƒ¼ã®è² è·é‡_ä¸€è¦§.csv", encoding="utf-8-sig")

    # å¯„ä¸ç‡
    expl_df = pd.DataFrame(
        expl.reshape(1, -1), columns=pc_cols, index=["ExplainedVariance"]
    )
    expl_df.to_csv(pca_dir / "ä¸»æˆåˆ†_å¯„ä¸ç‡.csv", encoding="utf-8-sig")

    # ã‚¹ã‚³ã‚¢æ¨ç§»ï¼ˆPC3ã¾ã§ï¼‰
    plt.figure(figsize=(12, 5))
    colors = ["#1f77b4", "#ff7f0e", "#2ca02c"]
    for i, pc in enumerate(pc_cols[:3]):
        plt.plot(
            score_df.index,
            score_df[pc],
            label=f"{pc} (å¯„ä¸:{expl[i]*100:.1f}%)",
            color=colors[i],
            lw=2,
        )
    plt.title("ä¸»æˆåˆ†ã‚¹ã‚³ã‚¢ã®æ¨ç§» (ã‚»ã‚¯ã‚¿ãƒ¼æ¨™æº–åŒ–å¾Œã®ç”Ÿå€¤)")
    plt.xlabel("æ—¥ä»˜")
    plt.ylabel("ä¸»æˆåˆ†ã‚¹ã‚³ã‚¢")
    plt.axhline(0, color="black", lw=1)
    plt.legend(loc="upper left", bbox_to_anchor=(1, 1))
    plt.grid(axis="y", alpha=0.3)
    plt.tight_layout()
    plt.savefig(pca_dir / "PCA_ã‚¹ã‚³ã‚¢æ¨ç§»_ç”Ÿå€¤.png")
    plt.close()

    # è² è·é‡TOP10ï¼ˆPC3ã¾ã§ï¼‰
    for i, pc in enumerate(pc_cols[:3]):
        plt.figure(figsize=(10, 5))
        loadings[pc].reindex(loadings[pc].abs().sort_values(ascending=False).index).head(
            10
        ).plot(kind="bar", color=colors[i])
        plt.title(f"{pc} ã‚»ã‚¯ã‚¿ãƒ¼ã®è² è·é‡ (å¯„ä¸:{expl[i]*100:.1f}%)")
        plt.xlabel("ã‚»ã‚¯ã‚¿ãƒ¼")
        plt.ylabel("è² è·é‡")
        plt.axhline(0, color="black", lw=1)
        plt.xticks(rotation=45, ha="right")
        plt.grid(axis="y", alpha=0.3)
        plt.tight_layout()
        plt.savefig(pca_dir / f"è² è·é‡_{pc}_TOP10.png")
        plt.close()

    print(f"âœ… PCAåˆ†æå®Œäº†: {pca_dir}")


# =========================================================
# 5. é›†è¨ˆãƒ»å¯è¦–åŒ–ï¼ˆâ€»ä¿å­˜åãƒ»ãƒ­ã‚¸ãƒƒã‚¯ç¶­æŒï¼‰
# =========================================================
def plot_abs_heatmaps(full_pca_df: pd.DataFrame, output_root: Path):
    for pc in ["PC1", "PC2", "PC3"]:
        target_df = full_pca_df[full_pca_df["PC_Type"] == pc]
        if target_df.empty:
            continue

        plot_data = target_df.drop(columns=["PC_Type", "Window", "Explained_Variance"]).T
        plot_data.columns = target_df["Window"]

        plt.figure(figsize=(14, 9))
        sns.heatmap(
            plot_data,
            cmap="Reds",
            annot=False,
            cbar_kws={"label": f"{pc} è² è·é‡ï¼ˆçµ¶å¯¾å€¤ï¼‰"},
            vmin=0,
            vmax=max(0.5, plot_data.max().max()),
        )

        mean_var = target_df["Explained_Variance"].mean() * 100
        plt.title(
            f"{pc} æ§‹æˆã‚»ã‚¯ã‚¿ãƒ¼ã®è² è·é‡æ¨ç§»ï¼ˆçµ¶å¯¾å€¤ï¼‰\n[å¹³å‡å¯„ä¸ç‡: {mean_var:.1f}%]",
            fontsize=14,
        )
        plt.xlabel("ãƒ†ã‚¹ãƒˆã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ (Window)", fontsize=12)
        plt.ylabel("ã‚»ã‚¯ã‚¿ãƒ¼", fontsize=12)
        plt.tight_layout()
        plt.savefig(output_root / f"å…¨æœŸé–“_{pc}_æ§‹é€ æ¨ç§»_çµ¶å¯¾å€¤.png")
        plt.close()


def plot_final_boxplots(merged_summary: pd.DataFrame, output_root: Path):
    plot_df_base = merged_summary.copy().reset_index(drop=True)
    targets = ["è¨“ç·´RMSE", "äºˆæ¸¬RMSE", "RMSEæ¯”", "AIC", "æœ€å¤§å›ºæœ‰å€¤"]

    for col in targets:
        if col not in plot_df_base.columns:
            continue

        plt.figure(figsize=(14, 8))
        plot_data = (
            plot_df_base[plot_df_base[col] != 0].copy()
            if col != "AIC"
            else plot_df_base.copy()
        )
        if plot_data.empty:
            continue

        order = plot_data.groupby("ãƒ¢ãƒ‡ãƒ«æ§‹æˆ")[col].mean().sort_values().index

        sns.boxplot(
            data=plot_data,
            x="ãƒ¢ãƒ‡ãƒ«æ§‹æˆ",
            y=col,
            order=order,
            palette="Set3",
            width=0.6,
            boxprops=dict(alpha=0.7),
        )
        sns.pointplot(
            data=plot_data,
            x="ãƒ¢ãƒ‡ãƒ«æ§‹æˆ",
            y=col,
            order=order,
            join=False,
            color="red",
            marker="D",
            scale=0.7,
            errorbar="sd",
            capsize=0.15,
            label="å¹³å‡ Â± æ¨™æº–åå·®",
        )

        plt.xticks(rotation=45, ha="right")
        plt.title(f"{col} ã®åˆ†å¸ƒã¨çµ±è¨ˆæŒ‡æ¨™ (å…¨ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦)\n[ç®±:åˆ†å¸ƒ, â—†:å¹³å‡, èµ¤ç¸¦ç·š:æ¨™æº–åå·®]", fontsize=14)
        plt.grid(axis="y", linestyle="--", alpha=0.4)
        plt.legend(loc="upper left")
        plt.tight_layout()
        plt.savefig(output_root / f"å…¨æœŸé–“_ãˆãˆæ„Ÿã˜ç®±ã²ã’_{col}.png", dpi=300)
        plt.close()


def visualize_model_performance(csv_path: Path):
    df = pd.read_csv(csv_path, index_col=0)
    output_dir = Path(csv_path).parent
    plt.style.use("ggplot")

    targets = ["äºˆæ¸¬RMSE", "AIC", "è¨“ç·´RMSE", "æœ€å¤§å›ºæœ‰å€¤", "RMSEæ¯”"]

    for col in targets:
        avg_col = f"{col}_å¹³å‡"
        std_col = f"{col}_æ¨™æº–åå·®"
        if avg_col not in df.columns:
            continue

        plt.figure(figsize=(12, 7))
        df_sorted = df.sort_values(avg_col)

        plt.bar(
            df_sorted.index,
            df_sorted[avg_col],
            yerr=df_sorted[std_col],
            capsize=5,
            color="skyblue",
            edgecolor="navy",
            alpha=0.7,
        )
        plt.xticks(rotation=45, ha="right")
        plt.ylabel(f"{col} (å¹³å‡)")
        plt.title(f"ãƒ¢ãƒ‡ãƒ«æ§‹æˆåˆ¥ {col} æ¯”è¼ƒ\n(ã‚¨ãƒ©ãƒ¼ãƒãƒ¼ã¯æ¨™æº–åå·®ã‚’è¡¨ç¤º)")
        plt.grid(axis="y", linestyle="--", alpha=0.7)
        plt.tight_layout()
        plt.savefig(output_dir / f"å…¨æœŸé–“_æ¯”è¼ƒ_{col}.png", dpi=300)
        plt.close()

    if "AIC_å¹³å‡" in df.columns and "äºˆæ¸¬RMSE_å¹³å‡" in df.columns:
        plt.figure(figsize=(10, 7))
        sns.scatterplot(
            data=df,
            x="AIC_å¹³å‡",
            y="äºˆæ¸¬RMSE_å¹³å‡",
            size="äºˆæ¸¬RMSE_æ¨™æº–åå·®",
            hue=df.index,
            sizes=(100, 1000),
            alpha=0.6,
        )
        for i, txt in enumerate(df.index):
            plt.annotate(
                txt,
                (df["AIC_å¹³å‡"].iloc[i], df["äºˆæ¸¬RMSE_å¹³å‡"].iloc[i]),
                xytext=(5, 5),
                textcoords="offset points",
                fontsize=8,
            )
        plt.title("ãƒ¢ãƒ‡ãƒ«ã®è¤‡é›‘ã•(AIC) vs äºˆæ¸¬ç²¾åº¦(RMSE)")
        plt.grid(True, alpha=0.3)
        plt.tight_layout()
        plt.savefig(output_dir / "å…¨æœŸé–“_AIC_vs_RMSE_åˆ†å¸ƒ.png", dpi=300)
        plt.close()

    print(f"ğŸ’¾ ã‚°ãƒ©ãƒ•ï¼ˆæ£’ã‚°ãƒ©ãƒ•5ç¨® ï¼‹ æ•£å¸ƒå›³1ç¨®ï¼‰ã‚’ {output_dir} ã«ä¿å­˜ã—ã¾ã—ãŸã€‚")


def aggregate_results(output_root: str | Path):
    output_root = Path(output_root)
    all_summaries = []
    pca_abs_details = []

    for window_path in sorted(output_root.glob("Window_Test_*")):
        window_name = window_path.name.replace("Window_Test_", "")

        # ãƒ¢ãƒ‡ãƒ«æ¯”è¼ƒã‚µãƒãƒªãƒ¼
        summary_file = window_path / "ãƒ¢ãƒ‡ãƒ«æ¯”è¼ƒã‚µãƒãƒªãƒ¼.csv"
        if summary_file.exists():
            df = pd.read_csv(summary_file)
            df["Test_Window"] = window_name
            all_summaries.append(df)

        # PCAè² è·é‡ï¼ˆçµ¶å¯¾å€¤ï¼‰& å¯„ä¸ç‡
        loadings_file = window_path / "pca_analysis" / "ã‚»ã‚¯ã‚¿ãƒ¼ã®è² è·é‡_ä¸€è¦§.csv"
        variance_file = window_path / "pca_analysis" / "ä¸»æˆåˆ†_å¯„ä¸ç‡.csv"
        if loadings_file.exists() and variance_file.exists():
            ld_df = pd.read_csv(loadings_file, index_col=0)
            vr_df = pd.read_csv(variance_file, index_col=0)
            for pc in ["PC1", "PC2", "PC3"]:
                if pc in ld_df.columns:
                    abs_row = ld_df[pc].abs().to_frame().T
                    abs_row.index = [f"{window_name}_{pc}"]
                    abs_row.insert(0, "Window", window_name)
                    abs_row.insert(1, "PC_Type", pc)
                    abs_row.insert(2, "Explained_Variance", vr_df.at["ExplainedVariance", pc])
                    pca_abs_details.append(abs_row)

    if not all_summaries:
        return

    merged_summary = pd.concat(all_summaries, ignore_index=True)

    # ãˆãˆæ„Ÿã˜ç®±ã²ã’ï¼ˆåŒã˜è¦‹ãŸç›®ï¼‰
    plot_final_boxplots(merged_summary, output_root)

    # çµ±è¨ˆè©³ç´°CSV
    target_cols = ["è¨“ç·´RMSE", "äºˆæ¸¬RMSE", "RMSEæ¯”", "AIC", "æœ€å¤§å›ºæœ‰å€¤"]
    stats_list = []
    for col in target_cols:
        if col not in merged_summary.columns:
            continue

        temp = merged_summary.copy()
        if col != "AIC":
            temp[col] = temp[col].replace(0, np.nan)

        res = temp.groupby("ãƒ¢ãƒ‡ãƒ«æ§‹æˆ")[col].agg(
            [
                (f"{col}_å¹³å‡", "mean"),
                (f"{col}_æ¨™æº–åå·®", "std"),
                (f"{col}_æœ€å¤§", "max"),
                (f"{col}_æœ€å°", "min"),
            ]
        )
        stats_list.append(res)

    model_perf_detail = pd.concat(stats_list, axis=1)
    model_perf_detail["æœ‰åŠ¹è©¦è¡Œå›æ•°"] = merged_summary.groupby("ãƒ¢ãƒ‡ãƒ«æ§‹æˆ")["äºˆæ¸¬RMSE"].apply(
        lambda x: (x != 0).sum()
    )
    model_perf_detail = model_perf_detail.round(4)
    model_perf_detail.to_csv(
        output_root / "å…¨ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦é›†è¨ˆ_ãƒ¢ãƒ‡ãƒ«è©•ä¾¡_è©³ç´°ç‰ˆ.csv", encoding="utf-8-sig"
    )

    # PCAæ§‹é€ 
    if pca_abs_details:
        full_pca_df = pd.concat(pca_abs_details)
        full_pca_df.to_csv(
            output_root / "å…¨ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦é›†è¨ˆ_PCAæ§‹é€ _çµ¶å¯¾å€¤è©³ç´°.csv",
            encoding="utf-8-sig",
        )
        plot_abs_heatmaps(full_pca_df, output_root)

    print("âœ… ã™ã¹ã¦ã®é›†è¨ˆãƒ»ç”»åƒä¿å­˜ï¼ˆãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ã€ç®±ã²ã’å›³ã€çµ±è¨ˆè©³ç´°ï¼‰ãŒå®Œäº†ã—ã¾ã—ãŸã€‚")


# =========================================================
# 6. ãƒ¡ã‚¤ãƒ³ï¼ˆâ€»å‡¦ç†é †ãƒ»ä¿å­˜ç‰©ãƒ»è¨ˆç®—ã¯åŒä¸€ï¼‰
# =========================================================
def main():
    df_raw = pd.read_csv(CONFIG["data_path"], index_col=0, parse_dates=True).sort_index()
    sector_df, macro_df, common_idx, meta = prepare_aligned(df_raw)

    test_len = 4
    n_total = len(common_idx)

    for i in range(n_total - test_len + 1):
        te_idx_list = np.arange(i, i + test_len)
        tr_idx_list = np.setdiff1d(np.arange(n_total), te_idx_list)

        d_start = common_idx[te_idx_list[0]]
        d_end = common_idx[te_idx_list[-1]]

        root_dir = Path(CONFIG["output_dir"]) / f"Window_Test_{d_start:%Y%m%d}_{d_end:%Y%m%d}"
        root_dir.mkdir(parents=True, exist_ok=True)

        print(f"â–¶ï¸ å®Ÿè¡Œä¸­: {root_dir.name}")

        # PCA: è¨“ç·´(tr_idx_list)ã§fitã—ã€å…¨æœŸé–“transform
        sc_pca = StandardScaler()
        X_tr_pca = sc_pca.fit_transform(sector_df.iloc[tr_idx_list])
        pca_temp = PCA().fit(X_tr_pca)
        n_pcs = max(3, np.argmax(np.cumsum(pca_temp.explained_variance_ratio_) >= 0.90) + 1)

        pca = PCA(n_components=n_pcs).fit(X_tr_pca)
        pc_cols_orig = [f"PC{k+1}" for k in range(n_pcs)]

        # å…¨æœŸé–“PCï¼ˆå·®åˆ†åŒ–ã€å…ˆé ­dropnaã€PC1-3ã®ã¿ï¼‰
        full_pcs = pca.transform(sc_pca.transform(sector_df))
        pc_diff_all = pd.DataFrame(full_pcs, index=sector_df.index).diff().dropna()
        pc_diff_all = pc_diff_all.iloc[:, :3]
        pc_cols_diff = [f"PC{k+1}_DIFF" for k in range(3)]
        pc_diff_all.columns = pc_cols_diff

        # PCAãƒ¬ãƒãƒ¼ãƒˆ
        analyze_pca_details(
            pca,
            sector_df,
            pc_cols_orig,
            root_dir,
            tr_idx_list[0],
            tr_idx_list[-1],
            test_len,
        )

        # åŒæœŸ
        m_df_win = macro_df.loc[pc_diff_all.index]
        combinations = [[]] + [
            list(c) for r in range(1, 4) for c in itertools.combinations(pc_cols_diff, r)
        ]

        summary_list = []
        m_cols = list(macro_df.columns)
        m_dim = len(m_cols)

        for combo in combinations:
            m_name_display = ", ".join(combo) if combo else "ãƒã‚¯ãƒ­ã®ã¿"
            sub_dir = root_dir / ("_".join(combo) if combo else "BASE_VAR_ONLY")
            sub_dir.mkdir(parents=True, exist_ok=True)

            win_idx = m_df_win.index

            tr_pre_dates = common_idx[tr_idx_list[tr_idx_list < te_idx_list[0]]]
            tr_post_dates = common_idx[tr_idx_list[tr_idx_list > te_idx_list[-1]]]
            te_dates = common_idx[te_idx_list]

            # éå»å´è¨“ç·´
            tr_pre = pd.concat(
                [
                    m_df_win.loc[win_idx.isin(tr_pre_dates)],
                    pc_diff_all.loc[win_idx.isin(tr_pre_dates), combo],
                ],
                axis=1,
            )

            # æœªæ¥å´è¨“ç·´
            tr_post = pd.concat(
                [
                    m_df_win.loc[win_idx.isin(tr_post_dates)],
                    pc_diff_all.loc[win_idx.isin(tr_post_dates), combo],
                ],
                axis=1,
            )

            # å…ƒãƒ­ã‚¸ãƒƒã‚¯ï¼šæœªæ¥å´å…ˆé ­ã‚’NaNã«ã—ã¦ã€Œå£ã€ã‚’ä½œã‚‹
            if not tr_post.empty:
                tr_post.iloc[0, :] = np.nan

            tr_raw = pd.concat([tr_pre, tr_post])
            te_raw = pd.concat(
                [
                    m_df_win.loc[win_idx.isin(te_dates)],
                    pc_diff_all.loc[win_idx.isin(te_dates), combo],
                ],
                axis=1,
            )

            means = tr_raw.mean()
            stds = tr_raw.std(ddof=0).replace(0, 1.0)

            tr_s = (tr_raw - means) / stds
            te_s = (te_raw - means) / stds

            # æ¨å®š
            Y_tr, X_tr = make_design(tr_s[m_cols], tr_s[combo] if combo else None, CONFIG["p_lag"])
            Beta = np.linalg.solve(
                X_tr.T @ X_tr + CONFIG["ridge"] * np.eye(X_tr.shape[1]),
                X_tr.T @ Y_tr,
            )

            # æŒ‡æ¨™
            tr_resid = Y_tr - X_tr @ Beta
            n_obs = len(Y_tr)
            tr_rmse = np.sqrt(np.mean(tr_resid ** 2))

            Y_te, X_te = make_design(te_s[m_cols], te_s[combo] if combo else None, CONFIG["p_lag"])
            te_rmse = np.sqrt(np.mean((Y_te - X_te @ Beta) ** 2)) if len(Y_te) > 0 else np.nan

            sigma_matrix = (tr_resid.T @ tr_resid) / n_obs
            sign, logdet = np.linalg.slogdet(sigma_matrix)
            if sign > 0:
                aic_val = n_obs * logdet + 2 * Beta.size
            else:
                eigs = np.linalg.eigvalsh(sigma_matrix)
                valid_eigs = eigs[eigs > 1e-15]
                aic_val = n_obs * np.sum(np.log(valid_eigs)) + 2 * Beta.size if len(valid_eigs) > 0 else np.nan

            A1 = Beta[1 : 1 + m_dim, :].T
            max_eig_abs = np.max(np.abs(np.linalg.eigvals(A1)))

            summary_list.append(
                {
                    "ãƒ¢ãƒ‡ãƒ«æ§‹æˆ": m_name_display,
                    "è¨“ç·´RMSE": round(tr_rmse, 4),
                    "äºˆæ¸¬RMSE": round(te_rmse, 4) if not np.isnan(te_rmse) else np.nan,
                    "RMSEæ¯”": round(te_rmse / tr_rmse, 2)
                    if tr_rmse > 0 and not np.isnan(te_rmse)
                    else np.nan,
                    "AIC": round(aic_val, 2) if not np.isnan(aic_val) else np.nan,
                    "æœ€å¤§å›ºæœ‰å€¤": round(max_eig_abs, 3),
                }
            )

            # IRFï¼ˆå…ƒã®ã¾ã¾ï¼‰
            if CONFIG["do_irf"] and combo:
                B = Beta[1 + m_dim :, :].T
                for j, pc_label in enumerate(combo):
                    pc_folder = sub_dir / f"Shock_{pc_label}"
                    pc_folder.mkdir(parents=True, exist_ok=True)

                    impact = np.zeros((13, m_dim))
                    impact[1] = B[:, j]
                    for h in range(2, 13):
                        impact[h] = A1 @ impact[h - 1]

                    for i_m, m_col in enumerate(m_cols):
                        orig_m, meth_m = meta[m_col]["orig"], meta[m_col]["method"]
                        base = BASE_LEVELS.get(orig_m, 100)
                        imp_raw = impact[:, i_m] * stds[m_col]

                        vals = [base]
                        for s in range(1, 13):
                            vals.append(
                                vals[-1] * np.exp(imp_raw[s]) if meth_m == "LOGDIFF" else vals[-1] + imp_raw[s]
                            )

                        plt.figure(figsize=(6, 3.5))
                        ax = plt.gca()
                        ax.yaxis.get_major_formatter().set_useOffset(False)
                        ax.yaxis.get_major_formatter().set_scientific(False)

                        plt.plot(range(13), vals, color="k", lw=1)
                        plt.scatter(range(13), vals, marker="o", s=15, color="k", zorder=2)
                        plt.scatter(1, vals[1], facecolors="none", edgecolors="k", marker="o", s=100, lw=1, zorder=3)
                        plt.axvline(x=1, color="k", ls="--", lw=0.7, alpha=0.6)
                        plt.axhline(base, color="gray", ls=":", lw=0.8)
                        plt.title(f"{pc_label} â†’ {orig_m}")
                        plt.grid(alpha=0.15)
                        plt.tight_layout()
                        plt.savefig(pc_folder / f"{orig_m}_å¿œç­”.png")
                        plt.close()

        pd.DataFrame(summary_list).sort_values("AIC").to_csv(
            root_dir / "ãƒ¢ãƒ‡ãƒ«æ¯”è¼ƒã‚µãƒãƒªãƒ¼.csv", index=False, encoding="utf-8-sig"
        )

    # å…¨ä½“é›†è¨ˆ
    aggregate_results(CONFIG["output_dir"])

    # è¿½åŠ å¯è¦–åŒ–
    output_folder = Path(CONFIG["output_dir"])
    csv_file = output_folder / "å…¨ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦é›†è¨ˆ_ãƒ¢ãƒ‡ãƒ«è©•ä¾¡_è©³ç´°ç‰ˆ.csv"
    if csv_file.exists():
        visualize_model_performance(csv_file)

    print("âœ… å…¨å·¥ç¨‹å®Œäº†ã€‚ç”»åƒã¨CSVã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")


if __name__ == "__main__":
    main()